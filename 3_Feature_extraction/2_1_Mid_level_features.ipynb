{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Zk9_ZongDh8P"},"outputs":[],"source":[" ### Imports general ###\n","#######################\n","\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import shutil\n","import os\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16700,"status":"ok","timestamp":1689776549128,"user":{"displayName":"Sebastian Maier","userId":"16903936560471934380"},"user_tz":-120},"id":"tWXTZG4JEUjE","outputId":"56d461cc-16a3-41b9-b6f0-02c6e8e0fb14"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["### Set data directory\n","##################\n","\n","# connect to drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# set data directory\n","data_dir = '/content/drive/MyDrive/0_Masterarbeit/2_Pipelines/Data'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4TV3eP3HEggI"},"outputs":[],"source":["### Upload video and audio files ###\n","####################################\n","\n","data_file = 'ferrari'\n","\n","# copy zip files\n","shutil.copy(os.path.join(data_dir, f'Video_{data_file}.zip'), './')\n","shutil.copy(os.path.join(data_dir, f'Audio_{data_file}.zip'), './')\n","\n","# create folders to unpack zip files to\n","os.makedirs('./Video')\n","os.makedirs('./Audio')\n","\n","# unpack zip files\n","shutil.unpack_archive(f'./Video_{data_file}.zip', extract_dir = './Video')\n","shutil.unpack_archive(f'./Audio_{data_file}.zip', extract_dir = './Audio')"]},{"cell_type":"markdown","metadata":{"id":"VKVqeT5uG4R5"},"source":["### Action detection"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6682,"status":"ok","timestamp":1689776590273,"user":{"displayName":"Sebastian Maier","userId":"16903936560471934380"},"user_tz":-120},"id":"1cIGI1ujHZOJ","outputId":"10f6464b-3357-4b1a-ea06-4a9e338c3219"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scenedetect[opencv]\n","  Downloading scenedetect-0.6.1-py3-none-any.whl (115 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/115.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from scenedetect[opencv]) (8.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scenedetect[opencv]) (1.22.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scenedetect[opencv]) (4.65.0)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from scenedetect[opencv]) (1.4.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from scenedetect[opencv]) (4.7.0.72)\n","Installing collected packages: scenedetect\n","Successfully installed scenedetect-0.6.1\n"]}],"source":["### Installation scene detection ###\n","####################################\n","\n","!pip install --upgrade scenedetect[opencv]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":872,"status":"ok","timestamp":1689776591132,"user":{"displayName":"Sebastian Maier","userId":"16903936560471934380"},"user_tz":-120},"id":"wX_jlulLHD5P","outputId":"58ecbfb1-b861-4291-8724-b690d9685ebe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'moments_models'...\n","remote: Enumerating objects: 139, done.\u001b[K\n","remote: Counting objects: 100% (60/60), done.\u001b[K\n","remote: Compressing objects: 100% (17/17), done.\u001b[K\n","remote: Total 139 (delta 53), reused 43 (delta 43), pack-reused 79\u001b[K\n","Receiving objects: 100% (139/139), 58.78 KiB | 3.46 MiB/s, done.\n","Resolving deltas: 100% (75/75), done.\n"]}],"source":["### Clone git repo ###\n","######################\n","\n","# clone\n","!git clone https://github.com/metalbubble/moments_models.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gg2nGUySHOvI"},"outputs":[],"source":["### Imports for action detection ###\n","####################################\n","\n","# scene detection\n","from scenedetect import detect, ContentDetector\n","\n","# action detection model\n","from moments_models import models\n","import torch\n","from torch.nn import functional as F\n","from torchvision import transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNenji_ZIAeF"},"outputs":[],"source":["### Load model ###\n","##################\n","\n","# model\n","model = models.load_model('multi_resnet3d50')\n","\n","# categories\n","categories = models.load_categories('./moments_models/category_multi_momentsv2.txt')\n","\n","# load transform\n","transform = transforms.Compose([transforms.ToPILImage(),\n","                                transforms.Resize((224, 224)),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize([0.485, 0.456, 0.406],\n","                                                     [0.229, 0.224, 0.225])])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G_0vofewIfTN"},"outputs":[],"source":["### Function to apply action detection model to individual scenes ###\n","#####################################################################\n","\n","def action_detection(video_file):\n","\n","\n","  ### Scelect sample frames for each video ###\n","  ############################################\n","\n","  # detect scenes\n","  scene_list = detect(video_file, ContentDetector())\n","\n","  # if no scenes detected -> eg. whole video in one shot\n","  if len(scene_list) == 0:\n","\n","    # extract number of frames in the video\n","    cap = cv2.VideoCapture(video_file)\n","    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    cap.release()\n","\n","\n","\n","    if num_frames >= 144:\n","\n","      # split the video in 9 equal parts\n","      equal_parts = list(np.linspace(0, num_frames, 10, dtype = int))\n","\n","      # extract tupels of first and last scene for each part\n","      scene_list = [(start, stop) for start, stop in zip(equal_parts, equal_parts[1:])]\n","\n","      # select every third part to be analyzed\n","      scene_list = [scene_list[j] for j in range(0, len(scene_list), 3)]\n","\n","    else:\n","      # split the video in 6 equal parts\n","      equal_parts = list(np.linspace(0, num_frames, 7, dtype = int))\n","\n","      # extract tupels of first and last scene for each part\n","      scene_list = [(start, stop) for start, stop in zip(equal_parts, equal_parts[1:])]\n","\n","      # select every third part to be analyzed\n","      scene_list = [scene_list[j] for j in range(0, len(scene_list), 2)]\n","\n","\n","    # get list of start frames of each part\n","    scene_start_frames = [i[0] for i in scene_list]\n","\n","    # get list of part lengths in num frames\n","    scene_len_in_frames = [i[1] - i[0] for i in scene_list]\n","\n","  else: # scenes detected\n","\n","    # select every third scene to be analyzed\n","    scene_list = [scene_list[j] for j in range(0, len(scene_list), 3)]\n","\n","    # get list of start frames for each scene\n","    scene_start_frames = [i[0].get_frames() for i in scene_list]\n","\n","    # get list of scene lengths in num frames\n","    scene_len_in_frames = [i[1].get_frames() - i[0].get_frames() for i in scene_list]\n","\n","\n","  # get list of 16 subsequent sample frames for each scene as required by the model\n","  sample_frames_per_scene = []\n","  for i, j in zip(scene_start_frames, scene_len_in_frames):\n","\n","    if j >= 16: # only consider scenes that include at least 16 frames\n","      sample_frames_per_scene.append(\n","         list(np.linspace(i, i+j-1, 16, dtype = int))\n","         )\n","\n","  ### Extract the selected sample frames per scene ###\n","  ####################################################\n","\n","  cap = cv2.VideoCapture(video_file)\n","\n","  scene_frames = []\n","  for l in sample_frames_per_scene:\n","\n","    rgb_frames = []\n","    for f in l:\n","      # set to position of respective sample frame\n","      cap.set(cv2.CAP_PROP_POS_FRAMES, f)\n","\n","      # Read the frame from the video\n","      ret, frame = cap.read()\n","\n","      # convert frame array to RGB format\n","      img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","      rgb_frames.append(img)\n","\n","    scene_frames.append(rgb_frames)\n","\n","\n","  # Release the video capture object and close the windows\n","  cap.release()\n","  cv2.destroyAllWindows()\n","\n","\n","\n","  ### Predict category probabilities and average over video ###\n","  #############################################################\n","\n","  for i, frs in enumerate(scene_frames):\n","\n","    # create transformed model input of 16 subsequent frames per scene to get prediction for scene\n","    input = torch.stack([transform(frame) for frame in frs], 1).unsqueeze(0)\n","\n","    # Make video prediction\n","    with torch.no_grad():\n","      logits = model(input) # extract logits\n","      h_x = F.softmax(logits, 1).mean(dim=0) # convert logits to class probabilities\n","\n","    # sum class probabilities over all scenes\n","    if i==0:\n","      average_probs = h_x\n","\n","    else:\n","      average_probs += h_x\n","\n","  # average class probabilities by number of considered scenes\n","  average_probs /= len(sample_frames_per_scene)\n","\n","  return average_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6gGM8zY7lEi"},"outputs":[],"source":["os.remove(os.path.join('./Video', '_5vL2OVxwEw.mp4'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"rSCSt4SSccXo","outputId":"e30483a8-ee7a-495c-e3f0-e10fea7f6ef2"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/182 [00:00<?, ?it/s]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  1%|          | 1/182 [01:04<3:15:27, 64.79s/it]INFO:pyscenedetect:Detecting scenes...\n","  1%|          | 2/182 [01:18<1:45:02, 35.02s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  2%|▏         | 3/182 [02:19<2:19:52, 46.89s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  2%|▏         | 4/182 [03:05<2:16:59, 46.18s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  3%|▎         | 5/182 [03:39<2:03:25, 41.84s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  3%|▎         | 6/182 [04:30<2:12:26, 45.15s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  4%|▍         | 7/182 [05:15<2:11:07, 44.96s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  4%|▍         | 8/182 [05:59<2:09:30, 44.66s/it]INFO:pyscenedetect:Detecting scenes...\n","  5%|▍         | 9/182 [06:21<1:48:30, 37.63s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  5%|▌         | 10/182 [06:42<1:33:24, 32.58s/it]INFO:pyscenedetect:Detecting scenes...\n","  6%|▌         | 11/182 [07:41<1:55:28, 40.52s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  7%|▋         | 12/182 [07:52<1:29:21, 31.54s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  7%|▋         | 13/182 [08:10<1:17:38, 27.57s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  8%|▊         | 14/182 [08:39<1:18:26, 28.01s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n","  8%|▊         | 15/182 [09:02<1:13:45, 26.50s/it]INFO:pyscenedetect:Detecting scenes...\n","  9%|▉         | 16/182 [09:24<1:09:35, 25.15s/it]INFO:pyscenedetect:Detecting scenes...\n","  9%|▉         | 17/182 [09:36<57:41, 20.98s/it]  INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 10%|▉         | 18/182 [09:50<52:05, 19.05s/it]INFO:pyscenedetect:Detecting scenes...\n"," 10%|█         | 19/182 [10:06<49:17, 18.15s/it]INFO:pyscenedetect:Detecting scenes...\n"," 11%|█         | 20/182 [10:30<53:57, 19.98s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 12%|█▏        | 21/182 [10:46<49:59, 18.63s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 12%|█▏        | 22/182 [11:25<1:06:05, 24.78s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 13%|█▎        | 23/182 [11:54<1:09:11, 26.11s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 13%|█▎        | 24/182 [12:32<1:17:54, 29.59s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 14%|█▎        | 25/182 [12:57<1:13:59, 28.28s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 14%|█▍        | 26/182 [13:35<1:21:12, 31.23s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 15%|█▍        | 27/182 [13:51<1:08:37, 26.57s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 15%|█▌        | 28/182 [14:20<1:09:50, 27.21s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 16%|█▌        | 29/182 [15:46<1:54:45, 45.01s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 16%|█▋        | 30/182 [16:25<1:49:26, 43.20s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 17%|█▋        | 31/182 [16:41<1:28:00, 34.97s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 18%|█▊        | 32/182 [17:22<1:31:37, 36.65s/it]INFO:pyscenedetect:Detecting scenes...\n"," 18%|█▊        | 33/182 [17:34<1:12:57, 29.38s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 19%|█▊        | 34/182 [17:52<1:04:07, 26.00s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 19%|█▉        | 35/182 [18:17<1:03:02, 25.73s/it]INFO:pyscenedetect:Detecting scenes...\n"," 20%|█▉        | 36/182 [18:29<52:15, 21.48s/it]  INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 20%|██        | 37/182 [19:14<1:09:14, 28.65s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 21%|██        | 38/182 [19:28<57:50, 24.10s/it]  INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 21%|██▏       | 39/182 [19:42<50:47, 21.31s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 22%|██▏       | 40/182 [19:55<44:33, 18.83s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 23%|██▎       | 41/182 [20:11<42:13, 17.97s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 23%|██▎       | 42/182 [20:55<59:44, 25.60s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 24%|██▎       | 43/182 [21:20<59:14, 25.57s/it]INFO:pyscenedetect:Detecting scenes...\n"," 24%|██▍       | 44/182 [21:34<50:28, 21.94s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 25%|██▍       | 45/182 [22:13<1:02:01, 27.16s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 25%|██▌       | 46/182 [22:35<58:08, 25.65s/it]  INFO:pyscenedetect:Detecting scenes...\n"," 26%|██▌       | 47/182 [23:01<57:48, 25.69s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 26%|██▋       | 48/182 [23:21<53:40, 24.03s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 27%|██▋       | 49/182 [23:37<47:37, 21.48s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 27%|██▋       | 50/182 [23:51<42:43, 19.42s/it]INFO:pyscenedetect:Detecting scenes...\n"," 28%|██▊       | 51/182 [24:03<37:11, 17.03s/it]INFO:pyscenedetect:Detecting scenes...\n"," 29%|██▊       | 52/182 [24:15<33:39, 15.53s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 29%|██▉       | 53/182 [24:43<41:34, 19.34s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 30%|██▉       | 54/182 [25:01<40:11, 18.84s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 30%|███       | 55/182 [25:24<42:44, 20.19s/it]INFO:pyscenedetect:Detecting scenes...\n"," 31%|███       | 56/182 [25:34<35:52, 17.08s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 31%|███▏      | 57/182 [25:59<40:17, 19.34s/it]INFO:pyscenedetect:Detecting scenes...\n"," 32%|███▏      | 58/182 [26:11<35:45, 17.30s/it]INFO:pyscenedetect:Detecting scenes...\n"," 32%|███▏      | 59/182 [26:30<36:21, 17.74s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 33%|███▎      | 60/182 [27:01<44:06, 21.69s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 34%|███▎      | 61/182 [27:40<54:31, 27.03s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 34%|███▍      | 62/182 [28:12<56:53, 28.44s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 35%|███▍      | 63/182 [29:41<1:32:18, 46.54s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 35%|███▌      | 64/182 [30:03<1:16:58, 39.14s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 36%|███▌      | 65/182 [30:24<1:05:54, 33.80s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 36%|███▋      | 66/182 [30:54<1:03:09, 32.67s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 37%|███▋      | 67/182 [31:22<59:48, 31.20s/it]  INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 37%|███▋      | 68/182 [31:41<52:39, 27.71s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 38%|███▊      | 69/182 [31:57<45:26, 24.13s/it]INFO:pyscenedetect:Detecting scenes...\n"," 38%|███▊      | 70/182 [32:15<41:43, 22.35s/it]INFO:pyscenedetect:Detecting scenes...\n"," 39%|███▉      | 71/182 [32:59<53:00, 28.66s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 40%|███▉      | 72/182 [33:07<41:18, 22.54s/it]INFO:pyscenedetect:Detecting scenes...\n"," 40%|████      | 73/182 [33:17<34:08, 18.79s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 41%|████      | 74/182 [33:35<33:33, 18.65s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 41%|████      | 75/182 [34:13<43:14, 24.25s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 42%|████▏     | 76/182 [34:49<49:24, 27.97s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 42%|████▏     | 77/182 [35:10<45:09, 25.80s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 43%|████▎     | 78/182 [35:31<41:59, 24.22s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 43%|████▎     | 79/182 [36:20<54:47, 31.92s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 44%|████▍     | 80/182 [36:57<56:39, 33.33s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 45%|████▍     | 81/182 [38:32<1:27:00, 51.69s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 45%|████▌     | 82/182 [38:47<1:08:06, 40.86s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 46%|████▌     | 83/182 [39:15<1:00:50, 36.87s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 46%|████▌     | 84/182 [39:26<47:26, 29.04s/it]  INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 47%|████▋     | 85/182 [39:39<39:12, 24.25s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 47%|████▋     | 86/182 [40:35<54:20, 33.97s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 360\n","INFO:pyscenedetect:Detecting scenes...\n"," 48%|████▊     | 87/182 [40:49<44:07, 27.87s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 48%|████▊     | 88/182 [41:18<44:12, 28.22s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 49%|████▉     | 89/182 [41:35<38:36, 24.91s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 49%|████▉     | 90/182 [41:46<31:59, 20.86s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 50%|█████     | 91/182 [42:10<33:02, 21.79s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 51%|█████     | 92/182 [42:31<32:17, 21.53s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 51%|█████     | 93/182 [43:13<40:50, 27.53s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 52%|█████▏    | 94/182 [43:44<41:47, 28.50s/it]INFO:pyscenedetect:Detecting scenes...\n"," 52%|█████▏    | 95/182 [44:13<41:34, 28.68s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 53%|█████▎    | 96/182 [44:20<32:03, 22.36s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 53%|█████▎    | 97/182 [45:33<53:03, 37.46s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 54%|█████▍    | 98/182 [46:05<50:07, 35.80s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 54%|█████▍    | 99/182 [46:30<45:07, 32.62s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 55%|█████▍    | 100/182 [47:26<54:04, 39.57s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 55%|█████▌    | 101/182 [47:47<45:45, 33.90s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 56%|█████▌    | 102/182 [48:21<45:15, 33.94s/it]INFO:pyscenedetect:Detecting scenes...\n"," 57%|█████▋    | 103/182 [48:36<37:18, 28.34s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 57%|█████▋    | 104/182 [48:55<33:01, 25.41s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 58%|█████▊    | 105/182 [49:17<31:17, 24.39s/it]INFO:pyscenedetect:Detecting scenes...\n"," 58%|█████▊    | 106/182 [49:25<24:58, 19.72s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 59%|█████▉    | 107/182 [50:12<34:35, 27.68s/it]INFO:pyscenedetect:Detecting scenes...\n"," 59%|█████▉    | 108/182 [50:25<28:49, 23.37s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 60%|█████▉    | 109/182 [50:50<29:08, 23.95s/it]INFO:pyscenedetect:Detecting scenes...\n"," 60%|██████    | 110/182 [51:16<29:29, 24.57s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 61%|██████    | 111/182 [51:37<27:48, 23.50s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 62%|██████▏   | 112/182 [52:05<28:46, 24.66s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 62%|██████▏   | 113/182 [52:32<29:20, 25.51s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 63%|██████▎   | 114/182 [52:52<26:53, 23.72s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 63%|██████▎   | 115/182 [53:08<23:52, 21.38s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 64%|██████▎   | 116/182 [54:00<33:46, 30.70s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 64%|██████▍   | 117/182 [54:12<27:07, 25.04s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 65%|██████▍   | 118/182 [54:31<24:51, 23.30s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 65%|██████▌   | 119/182 [54:54<24:20, 23.18s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 66%|██████▌   | 120/182 [55:35<29:20, 28.39s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 66%|██████▋   | 121/182 [56:05<29:36, 29.12s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 67%|██████▋   | 122/182 [56:31<27:55, 27.93s/it]INFO:pyscenedetect:Detecting scenes...\n"," 68%|██████▊   | 123/182 [57:14<32:00, 32.55s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 68%|██████▊   | 124/182 [57:24<24:53, 25.76s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 69%|██████▊   | 125/182 [57:39<21:20, 22.47s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 69%|██████▉   | 126/182 [57:58<20:00, 21.44s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 70%|██████▉   | 127/182 [58:12<17:50, 19.46s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 70%|███████   | 128/182 [58:26<15:53, 17.65s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 71%|███████   | 129/182 [59:07<21:52, 24.77s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 71%|███████▏  | 130/182 [59:27<20:09, 23.27s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 639\n","INFO:pyscenedetect:Detecting scenes...\n"," 72%|███████▏  | 131/182 [59:41<17:23, 20.46s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 73%|███████▎  | 132/182 [1:00:05<17:57, 21.56s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 73%|███████▎  | 133/182 [1:00:23<16:48, 20.58s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 74%|███████▎  | 134/182 [1:00:39<15:10, 18.97s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 74%|███████▍  | 135/182 [1:00:55<14:13, 18.15s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 360\n","INFO:pyscenedetect:Detecting scenes...\n"," 75%|███████▍  | 136/182 [1:01:34<18:38, 24.33s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 75%|███████▌  | 137/182 [1:01:50<16:31, 22.03s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 76%|███████▌  | 138/182 [1:02:18<17:21, 23.67s/it]INFO:pyscenedetect:Detecting scenes...\n"," 76%|███████▋  | 139/182 [1:03:12<23:34, 32.90s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 77%|███████▋  | 140/182 [1:03:47<23:27, 33.52s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 77%|███████▋  | 141/182 [1:04:00<18:40, 27.32s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 78%|███████▊  | 142/182 [1:05:14<27:38, 41.46s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 79%|███████▊  | 143/182 [1:05:37<23:17, 35.84s/it]INFO:pyscenedetect:Detecting scenes...\n"," 79%|███████▉  | 144/182 [1:06:15<23:09, 36.55s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 80%|███████▉  | 145/182 [1:06:42<20:38, 33.48s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 80%|████████  | 146/182 [1:06:57<16:47, 27.97s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 81%|████████  | 147/182 [1:07:29<17:06, 29.32s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 81%|████████▏ | 148/182 [1:07:49<15:02, 26.53s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 82%|████████▏ | 149/182 [1:08:14<14:18, 26.00s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 82%|████████▏ | 150/182 [1:08:37<13:24, 25.15s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 83%|████████▎ | 151/182 [1:09:10<14:08, 27.37s/it]INFO:pyscenedetect:Detecting scenes...\n"," 84%|████████▎ | 152/182 [1:09:30<12:38, 25.29s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 84%|████████▍ | 153/182 [1:09:38<09:38, 19.93s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 85%|████████▍ | 154/182 [1:11:10<19:27, 41.70s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 85%|████████▌ | 155/182 [1:11:46<18:02, 40.10s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 86%|████████▌ | 156/182 [1:12:22<16:47, 38.76s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 86%|████████▋ | 157/182 [1:12:53<15:08, 36.33s/it]INFO:pyscenedetect:Detecting scenes...\n"," 87%|████████▋ | 158/182 [1:13:08<11:56, 29.85s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 87%|████████▋ | 159/182 [1:13:29<10:31, 27.46s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 88%|████████▊ | 160/182 [1:13:54<09:46, 26.64s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 88%|████████▊ | 161/182 [1:14:10<08:13, 23.49s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 89%|████████▉ | 162/182 [1:14:36<08:03, 24.18s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 90%|████████▉ | 163/182 [1:15:27<10:10, 32.13s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 90%|█████████ | 164/182 [1:15:52<09:03, 30.18s/it]INFO:pyscenedetect:Detecting scenes...\n"," 91%|█████████ | 165/182 [1:16:06<07:07, 25.12s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 91%|█████████ | 166/182 [1:16:33<06:53, 25.85s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 92%|█████████▏| 167/182 [1:16:52<05:54, 23.65s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 92%|█████████▏| 168/182 [1:18:44<11:44, 50.34s/it]INFO:pyscenedetect:Detecting scenes...\n"," 93%|█████████▎| 169/182 [1:19:18<09:48, 45.26s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 93%|█████████▎| 170/182 [1:19:32<07:12, 36.04s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 94%|█████████▍| 171/182 [1:19:54<05:49, 31.74s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 95%|█████████▍| 172/182 [1:20:22<05:07, 30.76s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 95%|█████████▌| 173/182 [1:20:40<04:00, 26.76s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 96%|█████████▌| 174/182 [1:20:50<02:55, 21.88s/it]INFO:pyscenedetect:Detecting scenes...\n"," 96%|█████████▌| 175/182 [1:21:25<03:00, 25.79s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 97%|█████████▋| 176/182 [1:21:58<02:47, 27.84s/it]INFO:pyscenedetect:Detecting scenes...\n"," 97%|█████████▋| 177/182 [1:22:13<02:00, 24.15s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 98%|█████████▊| 178/182 [1:22:46<01:46, 26.67s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 98%|█████████▊| 179/182 [1:23:19<01:25, 28.62s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 99%|█████████▉| 180/182 [1:23:43<00:54, 27.04s/it]INFO:pyscenedetect:Downscale factor set to 2, effective resolution: 360 x 640\n","INFO:pyscenedetect:Detecting scenes...\n"," 99%|█████████▉| 181/182 [1:24:17<00:29, 29.38s/it]INFO:pyscenedetect:Detecting scenes...\n","100%|██████████| 182/182 [1:24:56<00:00, 28.00s/it]\n"]}],"source":["### Extract for each video ###\n","##############################\n","\n","video_id = []\n","action_probs = []\n","for video_file in tqdm(os.listdir('./Video')):\n","\n","  video_id.append(video_file[:-4])\n","  action_probs.append(action_detection(os.path.join('./Video', video_file)).tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Jt3OLvDifT-m"},"outputs":[],"source":["### Create final dataframe for action detection ###\n","###################################################\n","\n","action_df = pd.DataFrame(action_probs)\n","action_name_dict = {i:f\"p_action_{c}\" for i,c in enumerate(categories)}\n","action_df = action_df.rename(columns = action_name_dict)\n","action_df['video_id'] = video_id"]},{"cell_type":"markdown","metadata":{"id":"xvBNUpevhQGY"},"source":["### Face expression detection ###"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CJhBRwtbhPiA","outputId":"e26def79-b934-496b-dcd4-ecef669e27f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting face_detection\n","  Downloading face_detection-0.2.2.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from face_detection) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_detection) (0.15.2+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_detection) (1.22.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->face_detection) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->face_detection) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->face_detection) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->face_detection) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->face_detection) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->face_detection) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->face_detection) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->face_detection) (16.0.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.3.0->face_detection) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.3.0->face_detection) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->face_detection) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.3.0->face_detection) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.3.0->face_detection) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.3.0->face_detection) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.3.0->face_detection) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->face_detection) (1.3.0)\n","Building wheels for collected packages: face_detection\n","  Building wheel for face_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face_detection: filename=face_detection-0.2.2-py3-none-any.whl size=25560 sha256=4934e58b74e4dc59d227adcc306af1e5a7026f1b47eb4c7b4717b6192e7a9eaa\n","  Stored in directory: /root/.cache/pip/wheels/f9/14/a1/617e184738e71e46c1e75f068f67a911917ae5d02faeabc4e4\n","Successfully built face_detection\n","Installing collected packages: face_detection\n","Successfully installed face_detection-0.2.2\n","Collecting deepface\n","  Downloading deepface-0.0.79-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.22.4)\n","Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.5.3)\n","Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.65.0)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.6.6)\n","Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (8.4.0)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.7.0.72)\n","Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.12.0)\n","Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.12.0)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.5)\n","Collecting mtcnn>=0.1.0 (from deepface)\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting retina-face>=0.0.1 (from deepface)\n","  Downloading retina_face-0.0.13-py3-none-any.whl (16 kB)\n","Collecting fire>=0.4.0 (from deepface)\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gunicorn>=20.1.0 (from deepface)\n","  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.3.0)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.3.6)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.2)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.12.2)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (2.27.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.11.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (23.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2022.7.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.56.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.13)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (16.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (67.7.2)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.12.3)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.12.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.7.1)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=1.9.0->deepface) (1.10.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (3.4.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.7.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.4.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.3.1)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (3.2.2)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=0b46c9f9ca9fe22c31fe3b8afb72361c392f5abf2372bab19d111241e1716577\n","  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n","Successfully built fire\n","Installing collected packages: gunicorn, fire, mtcnn, retina-face, deepface\n","Successfully installed deepface-0.0.79 fire-0.5.0 gunicorn-21.2.0 mtcnn-0.1.1 retina-face-0.0.13\n"]}],"source":["### Installations face expression detection ###\n","###############################################\n","\n","!pip install face_detection\n","!pip install deepface"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"m4LaBTOuhscN","outputId":"521cd2e4-fb26-477e-e36c-551f7ab5a5f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory  /root /.deepface created\n","Directory  /root /.deepface/weights created\n"]}],"source":["### Imports face expression detection ###\n","#########################################\n","\n","import face_detection\n","from deepface import DeepFace"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ChWKOJMXh1-Y","outputId":"f09abd98-6fcd-499c-d6d0-1b463935d261"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://folk.ntnu.no/haakohu/RetinaFace_ResNet50.pth\" to /root/.cache/torch/hub/checkpoints/RetinaFace_ResNet50.pth\n","100%|██████████| 104M/104M [00:05<00:00, 20.3MB/s]\n"]}],"source":["### Load model ###\n","##################\n","\n","face_detector = face_detection.build_detector('RetinaNetResNet50', confidence_threshold=.8, nms_iou_threshold=.3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IOlDEOPhiFWd"},"outputs":[],"source":["### Function to detect faces in video and apply expression recognition  ###\n","###########################################################################\n","\n","def face_exp_detection(video_file):\n","\n","    # initialize video capturing object\n","    cap = cv2.VideoCapture(video_file)\n","\n","    # extract fps to set interval between frames to be contidered\n","    fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","    # frame interval -> every n = 2 second, a frame is considered in prediction\n","    frame_interval = 2 * fps\n","\n","    # initialize counter and emotion list object\n","    counter = 0\n","    expression_list = []\n","\n","    # loop though video\n","    while True:\n","      ret, frame = cap.read()\n","\n","      counter+=1\n","\n","      if not ret:\n","        break\n","\n","      if counter % frame_interval != 0:\n","        continue\n","\n","      # detect faces in frame\n","      det = face_detector.detect(frame)\n","\n","      # if no face detected continue with next frame\n","      if len(det) == 0:\n","        continue\n","\n","      # crop faces from frames and apply emotion classification\n","      for bbox in det:\n","\n","        # crop for face\n","        xmin, ymin, xmax, ymax , _ = bbox\n","        face = frame[abs(int(ymin)):abs(int(ymax)), abs(int(xmin)):abs(int(xmax))]\n","\n","        # apply emotion detection\n","        expression_det = DeepFace.analyze(face, actions = 'emotion', enforce_detection= False, silent = True)\n","\n","        expression_dict = expression_det[0]['emotion']\n","\n","        expression_list.append([expression_dict[emo] for emo in expression_dict])\n","\n","    # Release the video capture object and close the windows\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","    # if no face detected in the entire video -> return expression list of all 0's\n","    if len(expression_list) == 0:\n","       return [0,0,0,0,0,0,0]\n","\n","    # if one faces detected in video -> take mean over all class probabilities and devide by 100 (since model scales probs by 100)\n","    else:\n","      return list(np.array(expression_list).mean(0) / 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xww9vfO1i6c5"},"outputs":[],"source":["### Extract for each video ###\n","##############################\n","\n","video_id = []\n","exp_video_list = []\n","\n","for video_file in tqdm(os.listdir('./Video')):\n","\n","  video_id.append(video_file[:-4])\n","  exp_video_list.append(face_exp_detection(os.path.join('./Video', video_file)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXeotozSjgvt"},"outputs":[],"source":["### Create final dataframe for face expression detection ###\n","############################################################\n","# create df\n","face_exp_df = pd.DataFrame(exp_video_list)\n","\n","# create dict of col names\n","exp_classes = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n","exp_name_dict = {i:f\"p_face_{c}\" for i,c in enumerate(exp_classes)}\n","\n","# add names and video_id column\n","face_exp_df = face_exp_df.rename(columns = exp_name_dict)\n","face_exp_df['video_id'] = video_id"]},{"cell_type":"markdown","metadata":{"id":"um4YMm5_nEal"},"source":["### Scene Detection ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOgnGadJnC0q"},"outputs":[],"source":["### Installations scene detection ###\n","#####################################\n","\n","!pip uninstall -y transformers\n","!pip install transformers==4.28.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gu6JzLbSnxCa"},"outputs":[],"source":["### Imports scene detection ###\n","###############################\n","\n","from transformers import ViTForImageClassification, ViTFeatureExtractor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aGbYLlbQn8-M"},"outputs":[],"source":["### Load Model ###\n","##################\n","\n","# path to pre-trained model\n","scene_model_path = '/content/drive/MyDrive/0_Masterarbeit/2_Pipelines/Models/best_scene_detection_model'\n","\n","# classes to be detected\n","scene_classes = ['airport', 'alley', 'athlectic_field', 'auditorium', 'bar',\n","          'basketball_court', 'bathroom', 'beach', 'bedroom', 'bistro',\n","          'canyon', 'computer_room', 'desert', 'discotheque', 'factory',\n","          'field', 'forest', 'gym', 'harbor', 'highway', 'hill',\n","          'kitchen', 'lake', 'library', 'living_room', 'locker_room',\n","          'market', 'mountain', 'ocean', 'office', 'park', 'raceway',\n","          'river', 'skatepark', 'snowfield', 'stadium', 'street',\n","          'swimming_pool', 'tennis_court']\n","\n","# Load feature extractor\n","scene_feature_extractor = ViTFeatureExtractor.from_pretrained(scene_model_path)\n","\n","# Load model\n","scene_model = ViTForImageClassification.from_pretrained(\n","    scene_model_path,\n","    num_labels=len(scene_classes),\n","    id2label={str(i): c for i, c in enumerate(scene_classes)},\n","    label2id={c: str(i) for i, c in enumerate(scene_classes)}\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7o-48Hso_Sj"},"outputs":[],"source":["### Function to apply scene detection to video ###\n","##################################################\n","\n","def scene_detection(video_file):\n","\n","   # initialize video capturing object\n","    cap = cv2.VideoCapture(video_file)\n","\n","    # extract fps to set interval between frames to be contidered\n","    fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","    # frame interval -> every n = 2 second, a frame is considered in prediction\n","    frame_interval = 2 * fps\n","\n","    # initialize counter and scene list object\n","    counter = 0\n","    scene_list = []\n","\n","    # loop though video frame by frame\n","    while True:\n","      ret, frame = cap.read()\n","\n","      counter+=1\n","\n","      if not ret:\n","        break\n","\n","      # only consider first frame of every specified interval\n","      if counter % frame_interval != 0:\n","        continue\n","\n","\n","      # feature extraction\n","      inp = scene_feature_extractor(frame[:,:,::-1], return_tensors='pt')\n","\n","      # prediction\n","      with torch.no_grad():\n","\n","        # get model prediction as logits\n","        logits = scene_model(inp['pixel_values'])['logits']\n","\n","      # convert to class probabilities and save\n","      scene_list.append(logits.softmax(dim = -1)[0].tolist())\n","\n","\n","\n","    # Release the video capture object and close the windows\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","    # return mean of class probabilites over all considered frames\n","    return list(np.array(scene_list).mean(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uFBXf0LEqPhH"},"outputs":[],"source":["### Apply scene detection to all videos ###\n","###########################################\n","\n","video_id = []\n","scene_video_list = []\n","\n","for video_file in tqdm(os.listdir('./Video')):\n","\n","  video_id.append(video_file[:-4])\n","  scene_video_list.append(scene_detection(os.path.join('./Video', video_file)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m8feQY_crcXE"},"outputs":[],"source":["### Create final dataframe for scene detection ###\n","##################################################\n","\n","# create df\n","scene_df = pd.DataFrame(scene_video_list)\n","\n","# create dict of col names\n","scene_name_dict = {i:f\"p_scene_{c}\" for i,c in enumerate(scene_classes)}\n","\n","# add names and video_id column\n","scene_df = scene_df.rename(columns = scene_name_dict)\n","scene_df['video_id'] = video_id"]},{"cell_type":"markdown","metadata":{"id":"ZegbYD5LvsIs"},"source":["### Sound detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2TOSUrZWv3hI"},"outputs":[],"source":["### Import sound detection ###\n","##############################\n","\n","import librosa\n","from transformers import AutoFeatureExtractor, AutoModelForAudioClassification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"noEMy_AswPgE"},"outputs":[],"source":["### Load model ###\n","##################\n","\n","# path to pre-trained model\n","sound_model_path = '/content/drive/MyDrive/0_Masterarbeit/2_Pipelines/Models/best_sound_detection_model'\n","\n","# classes to be detected\n","sound_classes = ['airplane', 'angry voice', 'breathing', 'brushing_teeth', 'calm voice',\n","                'can_opening', 'car_horn', 'cat', 'chainsaw', 'chirping_birds',\n","                'church_bells', 'clapping', 'clock_alarm', 'clock_tick', 'coughing',\n","                'cow', 'crackling_fire', 'crickets', 'crow', 'crying_baby', 'dog',\n","                'door_wood_creaks', 'door_wood_knock', 'drinking_sipping', 'engine',\n","                'fireworks', 'footsteps', 'frog', 'glass_breaking', 'hand_saw',\n","                'happy voice', 'helicopter', 'hen', 'insects', 'keyboard_typing',\n","                'laughing', 'mouse_click', 'pig', 'pouring_water', 'rain', 'rooster',\n","                'sad voice', 'sea_waves', 'sheep', 'siren', 'sneezing', 'snoring',\n","                'thunderstorm', 'toilet_flush', 'train', 'vacuum_cleaner', 'washing_machine',\n","                'water_drops', 'wind']\n","\n","# Load feature extractor\n","sound_feature_extractor = AutoFeatureExtractor.from_pretrained(sound_model_path)\n","\n","# Load model\n","sound_model = AutoModelForAudioClassification.from_pretrained(sound_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JoaTsPA_wb4w"},"outputs":[],"source":["### Function to apply sound detection to video ###\n","##################################################\n","\n","def sound_detection(audio_file):\n","\n","  # load audio data\n","  audio_data, sr = librosa.load(audio_file)\n","\n","  # resample to sampling rate the model was trained on\n","  a_rs = librosa.resample(audio_data, orig_sr = sr, target_sr = 16000)\n","\n","  # split audio file into 10 parts of equal length\n","  parts = np.linspace(0, len(a_rs), 10)\n","\n","  # loop to consider each part individually\n","  audio_list = []\n","\n","  for i in [0, 3, 5, 7]:\n","\n","    # apply Short-time Fourier Transform to respective part to get model input\n","    inp = sound_feature_extractor(a_rs[int(parts[i]): int(parts[i+1])], sampling_rate=16000, return_tensors=\"pt\")\n","\n","    # extract class probabilities form output logits\n","    with torch.no_grad():\n","      class_probs = sound_model(**inp).logits.softmax(dim = -1)[0]\n","\n","    audio_list.append(class_probs.tolist())\n","\n","  # return mean class probabilites over all audio parts\n","  return list(np.array(audio_list).mean(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jn_7rqN-yTvD"},"outputs":[],"source":["### Apply sound detection to all audio files ###\n","################################################\n","\n","video_id = []\n","sound_video_list = []\n","\n","for audio_file in tqdm(os.listdir('./Audio')):\n","\n","  video_id.append(audio_file[:-4])\n","  sound_video_list.append(sound_detection(os.path.join('./Audio', audio_file)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0f_nJqR4QG8"},"outputs":[],"source":["### Create final dataframe for sound detection ###\n","##################################################\n","\n","# create df\n","sound_df = pd.DataFrame(sound_video_list)\n","\n","# create dict of col names\n","sound_name_dict = {i:f\"p_sound_{c}\" for i,c in enumerate(sound_classes)}\n","\n","# add names and video_id column\n","sound_df = sound_df.rename(columns = sound_name_dict)\n","sound_df['video_id'] = video_id"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"goSSQ6qe7c9g"},"outputs":[],"source":["### Merge all 4 dataframes into one ###\n","#######################################\n","\n","# merge\n","mid_level_features = action_df.merge(face_exp_df, on='video_id').merge(scene_df, on='video_id').merge(sound_df, on = 'video_id')\n","\n","# move video_id column to beginning\n","first_column = mid_level_features.pop('video_id')\n","mid_level_features.insert(0, 'video_id', first_column)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cT178wkhuSBq"},"outputs":[],"source":["### Save as csv file ###\n","########################\n","save_dir = '/content/drive/MyDrive/0_Masterarbeit/2_Pipelines/Feature_outputs'\n","\n","mid_level_features.to_csv(f'./mid_level_features_{data_file}.csv')\n","shutil.copy(f'./mid_level_features_{data_file}.csv', save_dir)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPIuiaM4nf5SeCLzFW90Exx"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZq0/viM8/bH7GJ22Pxmpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebi061/VideoAdEngagement/blob/main/2_Scrape_youtube_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Imports ###\n",
        "###############\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import requests\n",
        "import json\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "fohwzhU1Eyor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Set data directory\n",
        "##################\n",
        "\n",
        "# connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# set data directory\n",
        "data_dir = '/content/drive/MyDrive/0_Downloaded_Data/0_Video_Ad_Urls'\n",
        "save_dir = '/content/drive/MyDrive/0_Downloaded_Data/3_Engagement_Statistics'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF89IiDIIpkV",
        "outputId": "092f83f1-8ad2-4afe-b9b1-1da671220a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Select which brand types to scrape ###\n",
        "##########################################\n",
        "\n",
        "#brand_type = 'sports'\n",
        "brand_type = 'cars'"
      ],
      "metadata": {
        "id": "mp_yhDOw5ak6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Class to scrape data ###\n",
        "############################\n",
        "\n",
        "class YTVideostats:\n",
        "\n",
        "  def __init__(self, api_key, video_ids):\n",
        "    self.api_key = api_key\n",
        "    self.video_ids = video_ids\n",
        "\n",
        "  def get_video_data(self):\n",
        "\n",
        "    video_dict = {}\n",
        "\n",
        "    for id in self.video_ids:\n",
        "      video_dict[id] = dict()\n",
        "\n",
        "\n",
        "\n",
        "    parts = [\"snippet\", \"statistics\", \"contentDetails\"]\n",
        "\n",
        "    for video_id in tqdm(self.video_ids):\n",
        "      for part in parts:\n",
        "\n",
        "        data = self._get_single_video_data(video_id, part)\n",
        "        video_dict[video_id].update(data)\n",
        "\n",
        "\n",
        "\n",
        "    return video_dict\n",
        "\n",
        "  def _get_single_video_data(self, video_id, part):\n",
        "    url = f\"https://www.googleapis.com/youtube/v3/videos?part={part}&id={video_id}&key={self.api_key}\"\n",
        "\n",
        "    json_url = requests.get(url)\n",
        "    data = json.loads(json_url.text)\n",
        "    try:\n",
        "      data = data['items'][0][part]\n",
        "\n",
        "    except:\n",
        "      print('error')\n",
        "      data = dict()\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "_CMqXKfz2Jkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Brand channels to scrape from ###\n",
        "#####################################\n",
        "\n",
        "files_sports = ['nike', 'adidas', 'puma', 'underarmour',\n",
        "                'asics', 'converse', 'timberland', 'salomon',\n",
        "                'gymshark', 'gopro', 'redbull', 'monsterenergy']\n",
        "\n",
        "files_cars = ['hyundai', 'porsche', 'audi', 'bmw',\n",
        "              'vw', 'mercedes', 'honda', 'ford',\n",
        "              'skoda', 'ferrari']"
      ],
      "metadata": {
        "id": "qyqzUmRU1o39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_yt_stats(file, API_KEY):\n",
        "\n",
        "  # function to extract video id from video url\n",
        "  def extract_ids(example):\n",
        "    return example['video_url'][-11:]\n",
        "\n",
        "  # function to calculate engagement score from likes, comments and views\n",
        "  def engagement(example):\n",
        "    eng_score = (int(example['likes']) + int(example['comments'])) / int(example['views'])\n",
        "    return eng_score\n",
        "\n",
        "  # load dataframe\n",
        "  df = pd.read_csv(os.path.join(data_dir, f'videos_{file}.csv'))\n",
        "\n",
        "  # extract video id\n",
        "  df['video_id'] = df.apply(extract_ids, axis = 1)\n",
        "\n",
        "  # initialiize class to extract information from youtube\n",
        "\n",
        "  YT = YTVideostats(API_KEY, df.video_id)\n",
        "\n",
        "  # extract info to json df\n",
        "  json_ds_info = YT.get_video_data()\n",
        "\n",
        "  # extract stats info\n",
        "  info_stats = []\n",
        "\n",
        "  # extract brand name\n",
        "  brand = file\n",
        "\n",
        "  # extract stats info from json file\n",
        "  for key, value in json_ds_info.items():\n",
        "\n",
        "    views = value['viewCount']\n",
        "    likes = value['likeCount']\n",
        "    comments = value['commentCount']\n",
        "\n",
        "    info_stats.append([key, brand, views, likes, comments])\n",
        "\n",
        "\n",
        "  # create df of stats\n",
        "  df_scraped_stats = pd.DataFrame(info_stats, columns = [\"video_id\", \"brand\", \"views\", \"likes\", \"comments\"])\n",
        "  df_scraped_stats\n",
        "\n",
        "\n",
        "  # add engagement score\n",
        "  df_scraped_stats['eng_score'] = df_scraped_stats.apply(engagement, axis = 1)\n",
        "\n",
        "\n",
        "  return df_scraped_stats"
      ],
      "metadata": {
        "id": "qe4wq91Q-RtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Extract info from all videos and concat ###\n",
        "###############################################\n",
        "\n",
        "# my api key\n",
        "API_KEY =\n",
        "\n",
        "# assign files according to brand type selected before\n",
        "if brand_type == 'sports':\n",
        "  files = files_sports\n",
        "\n",
        "else:\n",
        "  files = files_cars\n",
        "\n",
        "\n",
        "# apply funtion to scrape data\n",
        "for i, file in enumerate(files):\n",
        "  if i == 0:\n",
        "    df_final = extract_yt_stats(file = file, API_KEY = API_KEY)\n",
        "\n",
        "  else:\n",
        "    df_additional = extract_yt_stats(file = file, API_KEY = API_KEY)\n",
        "    df_final = pd.concat([df_final, df_additional], ignore_index = True, axis = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HuQ6mvu4O3V",
        "outputId": "f8fee8d4-5415-4222-f7e0-c9cddc8de852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 106/106 [00:42<00:00,  2.48it/s]\n",
            "100%|██████████| 48/48 [00:19<00:00,  2.50it/s]\n",
            "100%|██████████| 86/86 [00:33<00:00,  2.60it/s]\n",
            "100%|██████████| 24/24 [00:09<00:00,  2.46it/s]\n",
            "100%|██████████| 90/90 [00:34<00:00,  2.63it/s]\n",
            "100%|██████████| 90/90 [00:37<00:00,  2.43it/s]\n",
            "100%|██████████| 51/51 [00:20<00:00,  2.51it/s]\n",
            "100%|██████████| 91/91 [00:36<00:00,  2.48it/s]\n",
            "100%|██████████| 26/26 [00:10<00:00,  2.44it/s]\n",
            "100%|██████████| 182/182 [01:12<00:00,  2.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Save ###\n",
        "############\n",
        "\n",
        "df_final.to_csv(f'./df_{brand_type}_stats.csv')"
      ],
      "metadata": {
        "id": "ChJINEKuECY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.copy(f'./df_{brand_type}_stats.csv', save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JNYnmkdPECUw",
        "outputId": "09fbad6b-20a1-4bc2-d094-1913cf6a1b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/0_Masterarbeit/2_Pipelines/Data/df_cars_stats.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}